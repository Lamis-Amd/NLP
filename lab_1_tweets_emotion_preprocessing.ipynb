{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KcTXCfJHtR1V"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsU90gi9x_Wt"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgDY8xN2xcLt",
        "outputId": "0c8ecb53-ee56-4d83-f9e2-3b47b6c9db7a"
      },
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "import os\n",
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SplYVf8Px9TK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2aedb4-c566-4872-859d-a896592457b7"
      },
      "source": [
        "drive.mount(\"/content/drive/\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "ldyUQ7YM0Fg5",
        "outputId": "c2f05f09-2f1f-4014-8d50-785ca7a9bec0"
      },
      "source": [
        "#load train data\n",
        "cols = ['id', 'tweet', 'emotion', 'intensity']\n",
        "path = \"/content/drive/My Drive/Tweet Emotion Intensity Dataset/\"\n",
        "anger_train = pd.read_csv(path + 'anger_train.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "fear_train = pd.read_csv(path + 'fear_train.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "sad_train = pd.read_csv(path + 'sadness_train.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "joy_train = pd.read_csv(path + 'joy_train.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "\n",
        "joy_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30000</th>\n",
              "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30001</th>\n",
              "      <td>Oh dear an evening of absolute hilarity I don'...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30002</th>\n",
              "      <td>Been waiting all week for this game â¤ï¸â¤ï...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30003</th>\n",
              "      <td>@gardiner_love : Thank you so much, Gloria! Yo...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30004</th>\n",
              "      <td>I feel so blessed to work with the family that...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30818</th>\n",
              "      <td>It's just the lack of company and liveliness o...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30819</th>\n",
              "      <td>Quinn's short hair makes me sad. #glee</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30820</th>\n",
              "      <td>hate overthinking e v e r y t h i n g like i j...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30821</th>\n",
              "      <td>People who cheer for sports teams completely o...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30822</th>\n",
              "      <td>@DamnPatriot You're a POS for rejoicing in som...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>823 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet emotion  intensity\n",
              "id                                                                         \n",
              "30000  Just got back from seeing @GaryDelaney in Burs...     joy      0.980\n",
              "30001  Oh dear an evening of absolute hilarity I don'...     joy      0.958\n",
              "30002  Been waiting all week for this game â¤ï¸â¤ï...     joy      0.940\n",
              "30003  @gardiner_love : Thank you so much, Gloria! Yo...     joy      0.938\n",
              "30004  I feel so blessed to work with the family that...     joy      0.938\n",
              "...                                                  ...     ...        ...\n",
              "30818  It's just the lack of company and liveliness o...     joy      0.058\n",
              "30819             Quinn's short hair makes me sad. #glee     joy      0.040\n",
              "30820  hate overthinking e v e r y t h i n g like i j...     joy      0.040\n",
              "30821  People who cheer for sports teams completely o...     joy      0.020\n",
              "30822  @DamnPatriot You're a POS for rejoicing in som...     joy      0.019\n",
              "\n",
              "[823 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "nqZKPwhqvIKv",
        "outputId": "3cbde3de-2ca0-4112-b2f5-c2445906ce75"
      },
      "source": [
        "j_tweet=joy_train['tweet']\n",
        "j_emotion=joy_train['emotion']\n",
        "plt.scatter(j_tweet, j_emotion)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 157 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 143 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 141 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 144 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 129 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 157 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 143 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 141 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 144 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 129 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyYSxHl-F0uV",
        "outputId": "07cebdd7-239a-4cd1-c66d-fbfdd70505ff"
      },
      "source": [
        "#gather training files in one\n",
        "frames_training = [anger_train, fear_train, sad_train, joy_train]\n",
        "data_training = pd.concat(frames_training)\n",
        "data_training.reset_index(inplace=True)\n",
        "data_training.emotion.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fear       1147\n",
              "anger       857\n",
              "joy         823\n",
              "sadness     786\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "P42PgAnWaEPp",
        "outputId": "431e3f9d-9f20-497f-e410-c28b0553bb21"
      },
      "source": [
        "data_training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000</td>\n",
              "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10001</td>\n",
              "      <td>So my Indian Uber driver just called someone t...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10002</td>\n",
              "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10003</td>\n",
              "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10004</td>\n",
              "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3608</th>\n",
              "      <td>30818</td>\n",
              "      <td>It's just the lack of company and liveliness o...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3609</th>\n",
              "      <td>30819</td>\n",
              "      <td>Quinn's short hair makes me sad. #glee</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3610</th>\n",
              "      <td>30820</td>\n",
              "      <td>hate overthinking e v e r y t h i n g like i j...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3611</th>\n",
              "      <td>30821</td>\n",
              "      <td>People who cheer for sports teams completely o...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3612</th>\n",
              "      <td>30822</td>\n",
              "      <td>@DamnPatriot You're a POS for rejoicing in som...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3613 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... intensity\n",
              "0     10000  ...     0.938\n",
              "1     10001  ...     0.896\n",
              "2     10002  ...     0.896\n",
              "3     10003  ...     0.896\n",
              "4     10004  ...     0.896\n",
              "...     ...  ...       ...\n",
              "3608  30818  ...     0.058\n",
              "3609  30819  ...     0.040\n",
              "3610  30820  ...     0.040\n",
              "3611  30821  ...     0.020\n",
              "3612  30822  ...     0.019\n",
              "\n",
              "[3613 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Iq4qeawAQk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "cM68_Tk3VNPC",
        "outputId": "a244b83a-a5c9-4f9b-ae07-ff70f3982f51"
      },
      "source": [
        "#load test data\n",
        "cols = ['id', 'tweet', 'emotion', 'intensity']\n",
        "path = \"/content/drive/My Drive/Tweet Emotion Intensity Dataset/\"\n",
        "anger_test = pd.read_csv(path + 'anger_test.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "fear_test = pd.read_csv(path + 'fear_test.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "sad_test = pd.read_csv(path + 'sad_test.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "joy_test = pd.read_csv(path + 'joy_test.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
        "\n",
        "joy_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30902</th>\n",
              "      <td>You must be knowing #blithe means (adj.)  Happ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30903</th>\n",
              "      <td>Old saying 'A #smile shared is one gained for ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30904</th>\n",
              "      <td>Bridget Jones' Baby was bloody hilarious ðŸ˜… ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30905</th>\n",
              "      <td>@Elaminova sparkling water makes your life spa...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30906</th>\n",
              "      <td>I'm tired of everybody telling me to chill out...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31611</th>\n",
              "      <td>With a very tired body and mind and sparkling ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31612</th>\n",
              "      <td>I refuse to be a chirp chirp girl</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31613</th>\n",
              "      <td>It was very hard to stifle my laughter after I...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31614</th>\n",
              "      <td>While I was walking, a little boy in a red shi...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31615</th>\n",
              "      <td>Asked one thing from our guys tonight and got ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweet emotion  intensity\n",
              "id                                                                         \n",
              "30902  You must be knowing #blithe means (adj.)  Happ...     joy      0.583\n",
              "30903  Old saying 'A #smile shared is one gained for ...     joy      0.500\n",
              "30904  Bridget Jones' Baby was bloody hilarious ðŸ˜… ...     joy      0.860\n",
              "30905  @Elaminova sparkling water makes your life spa...     joy      0.521\n",
              "30906  I'm tired of everybody telling me to chill out...     joy      0.042\n",
              "...                                                  ...     ...        ...\n",
              "31611  With a very tired body and mind and sparkling ...     joy      0.417\n",
              "31612                  I refuse to be a chirp chirp girl     joy      0.146\n",
              "31613  It was very hard to stifle my laughter after I...     joy      0.646\n",
              "31614  While I was walking, a little boy in a red shi...     joy      0.620\n",
              "31615  Asked one thing from our guys tonight and got ...     joy      0.580\n",
              "\n",
              "[714 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEsuXOg40LH4"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqneUbRnXTY2",
        "outputId": "ed10b114-cd8f-4409-8f63-10e3d8813c89"
      },
      "source": [
        "#gather test files in one\n",
        "frames_test = [anger_test, fear_test, sad_test, joy_test]\n",
        "data_test = pd.concat(frames_test)\n",
        "data_test.reset_index(inplace=True)\n",
        "data_test.emotion.value_counts()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fear       995\n",
              "anger      760\n",
              "joy        714\n",
              "sadness    673\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E88dB7eEGBx2",
        "outputId": "56a1cbd8-dcce-4e48-9e09-8ddf48633394"
      },
      "source": [
        "\n",
        "\n",
        "print(data_test)\n",
        "print(type(data_test))\n",
        "\n",
        "print(data_training)\n",
        "print(type(data_training))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id  ... intensity\n",
            "0     10941  ...     0.319\n",
            "1     10942  ...     0.144\n",
            "2     10943  ...     0.898\n",
            "3     10944  ...     0.271\n",
            "4     10945  ...     0.646\n",
            "...     ...  ...       ...\n",
            "3137  31611  ...     0.417\n",
            "3138  31612  ...     0.146\n",
            "3139  31613  ...     0.646\n",
            "3140  31614  ...     0.620\n",
            "3141  31615  ...     0.580\n",
            "\n",
            "[3142 rows x 4 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "         id  ... intensity\n",
            "0     10000  ...     0.938\n",
            "1     10001  ...     0.896\n",
            "2     10002  ...     0.896\n",
            "3     10003  ...     0.896\n",
            "4     10004  ...     0.896\n",
            "...     ...  ...       ...\n",
            "3608  30818  ...     0.058\n",
            "3609  30819  ...     0.040\n",
            "3610  30820  ...     0.040\n",
            "3611  30821  ...     0.020\n",
            "3612  30822  ...     0.019\n",
            "\n",
            "[3613 rows x 4 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1XxvDpfYixx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJqcix1yGSsC",
        "outputId": "36ff8f31-c6df-4d58-b22c-cf3bd5b5f5ab"
      },
      "source": [
        "#compine test and train sets in one dataset\n",
        "frames_all = [anger_train, fear_train, sad_train, joy_train,anger_test, fear_test, sad_test, joy_test]\n",
        "all_data = pd.concat(frames_all)\n",
        "all_data.reset_index(inplace=True)\n",
        "all_data.emotion.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fear       2142\n",
              "anger      1617\n",
              "joy        1537\n",
              "sadness    1459\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oycv-ZB2GhJG",
        "outputId": "ff31b449-ce99-403b-a182-8ec41e760a78"
      },
      "source": [
        "print(all_data.shape)\n",
        "print(type(all_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6755, 4)\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC2aB8t0cdXJ"
      },
      "source": [
        "#########################################untill here we have : data_test ,data_training ,all_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZhC3mQayg0T"
      },
      "source": [
        "**Cleaning the dataset**\n",
        "\n",
        "remove everything from the reviews but letters. This will involve removing all punctuation marks such as commas, question marks, etc. The `sub` function from the `re` module can be used to replace the punctuation marks. After removing the punctuation marks, convert all the reviews to lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNskle4wxyR1"
      },
      "source": [
        "\n",
        "import re\n",
        "#building the function\n",
        "def clean_data(review):\n",
        "    review = re.sub('[^a-zA-Z]', ' ',review)\n",
        "    review = review.lower()\n",
        "    return review\n",
        "#apply\n",
        "data_training['tweet'] = data_training['tweet'].apply(clean_data)\n",
        "data_test['tweet']=data_training['tweet'].apply(clean_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDdOXxCwzaS9"
      },
      "source": [
        "**Removing stop words**\n",
        "\n",
        "The tweets also contain common words such as ‘the’, ‘at’, Let’s get rid of those.\n",
        "To remove them, using (nltk). Let’s import the package and download the stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIWoJca-xyhk",
        "outputId": "d37f0728-db6a-45e0-82c3-8139f626c222"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTK8NVYJxyzp"
      },
      "source": [
        "#build the function\n",
        "\n",
        "def remove_stop_words(review):\n",
        "  review_minus_sw = []\n",
        "  stop_words = stopwords.words('english')\n",
        "  review = review.split()\n",
        "  review = [review_minus_sw.append(word) for word in review if word not in stop_words]\n",
        "  review = ' '.join(review_minus_sw)\n",
        "  return review\n",
        "\n",
        "  #apply\n",
        "data_training['tweet'] = data_training['tweet'].apply(remove_stop_words)\n",
        "data_test['tweet'] = data_training['tweet'].apply(remove_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jevXvkK21Idj"
      },
      "source": [
        "**Stemming and lemmatizing**\n",
        "\n",
        "\n",
        "Stemming : convert the words in the reviews to their root form.\n",
        "This process is important because it reduces the number of words that will be fed to the machine learning model.\n",
        "`nltk` can assist  in converting the words in their root form.\n",
        "This can be done using the `WordNetLemmatizer` utility.\n",
        " This can also be done using the `PorterStemmer`.\n",
        "Stemmers use algorithms to remove suffixes and prefixes from words and the final words may not be the dictionary representation of a word.\n",
        "for example:  example -> examp\n",
        "lemmatizers will usually convert a word to the dictionary representatio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC0ulgQnxzKk",
        "outputId": "9a32b096-d52f-4e73-9018-ef1be48dd985"
      },
      "source": [
        "#pply the `WordNetLemmatizer`\n",
        "#creating the function\n",
        "nltk.download('wordnet')\n",
        "#WordNet is a lexical database of English.\n",
        "#Using synsets, helps find conceptual relationships between words\n",
        "# such as hypernyms, hyponyms, synonyms, antonyms etc.\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "\n",
        "def lematize(review):\n",
        "    review = review.split()\n",
        "    review = [lemmatizer.lemmatize(w) for w in review]\n",
        "    review = ' '.join(review)\n",
        "    return review\n",
        "    #applying\n",
        "data_training['tweet'] = data_training['tweet'].apply(lematize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NB3MKQODUP9",
        "outputId": "2a1637cb-49ce-46b1-9aa8-d2e5be167b56"
      },
      "source": [
        "type(data_training['tweet'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isSx0TKPDpr-"
      },
      "source": [
        "**Creating a bag of words model**\n",
        "As of this moment, the reviews are still in text form. However, they have to be converted into some numeric representation before they can be passed to the machine learning model. A common way for representing the reviews is through the bag of words model. This is how the bag of words model is created:\n",
        "\n",
        "Group all the reviews into a corpus. A corpus simply means a collection of many documents in this case the reviews.\n",
        "Take all the words in the corpus and create a column with each word.\n",
        "Represent each review with a row.\n",
        "If a certain word exists in the review, represent it by a 1, and if the word doesn’t exist in the review, represent it with a 0.\n",
        "In the above representation, each word represents a single feature. The above process will result in a sparse matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp-hM_cB5Yri",
        "outputId": "7eb00ea9-1cb8-434b-cc60-fac2d063788b"
      },
      "source": [
        "corpus = list(data_training['tweet'])\n",
        "#type(corpus)\n",
        "corpus_test = list(data_test['tweet'])\n",
        "type(corpus_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgLKyEcSIrXz"
      },
      "source": [
        "The numerical representation mentioned above can be obtained using the `CountVectorizer` from Scikit-learn. The function requires us to define the maximum number of words that will be used in the bag of words. The next step is to fit the instantiated `CountVectorizer` to the reviews.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgAcbVyvxzTI"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-lSCxdiItRC"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#cv = CountVectorizer(max_features = 1000)\n",
        " # Stop words are common words in English that don't tell us anything about the polarity of a review.\n",
        "    # Such words include the, that, and a\n",
        "# Converts a collection of text documents to a matrix of token counts\n",
        "# max_features = maximum number of words we'd like to have in our bag of words model\n",
        "#X_train = cv.fit_transform(corpus).toarray()\n",
        "#X_train\n",
        "#y = data_training['emotion'].values\n",
        "\n",
        "#cv.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awonbIvdKWMx"
      },
      "source": [
        "**From occurrences to frequencies**\n",
        "dividing the total occurrences of a word by the total number of words. This results in new features known as tf, short for Term Frequencies. The problem with this is that common words will tend to have a higher tf. This challenge is addressed by downscaling the weight carried by the common words. The downscaling is referred to as tf–idf short for Term Frequency Inverse Document Frequency.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AcOlTLG1X5f"
      },
      "source": [
        "\n",
        "#from sklearn.feature_extraction.text import TfidfTransformer\n",
        "#tf_transformer = TfidfTransformer()\n",
        "#X = tf_transformer.fit_transform(X).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSsCev7ILFlS"
      },
      "source": [
        "**Fitting CountVectorizer followed by TfidfTransformer**\n",
        "\n",
        "Scikit-learn **TfidfVectorizer** used to apply both of them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lp9G-tQPxGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c45301-838b-42e9-9f05-8ad1655eaec6"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidfVectorizer = TfidfVectorizer(max_features =1000)\n",
        "X_train = tfidfVectorizer.fit_transform(corpus).toarray()\n",
        "\n",
        "\n",
        "x_test= tfidfVectorizer.fit_transform(corpus_test).toarray()\n",
        "x_test\n",
        "#X_train[0:10,0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkHslHuNL_fZ"
      },
      "source": [
        "#### the input now  training_data['emotion'] is clean  named  x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA35cHTBsACx"
      },
      "source": [
        "**Padding**\n",
        "\n",
        "At the moment each review is represented by a sequence of integers.\n",
        "The only problem here is that the sequences are of different lengths.\n",
        "the data passed to a machine learning model is of the same length.\n",
        "Therefore, the sequences have to be forced to be of the same length.\n",
        "This is done by padding shorter sequences with zeros and dropping off some integers on very long sequences.\n",
        "This means that we have to define the maximum length of every sequence. Let’s use 100 now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHZFSeSk2_Vh",
        "outputId": "911784d2-40ee-4a31-ef13-fb1e08a972e7"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_length = 164\n",
        "X_train_pad = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "x_test_pad = pad_sequences(x_test, maxlen=max_length, padding='post')\n",
        "X_train_pad[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1LfW7Lsg40e"
      },
      "source": [
        "X_train_pad = list(X_train_pad)\n",
        "x_test_pad = list(x_test_pad)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZtwmh7iVgdT"
      },
      "source": [
        "\n",
        "    ######  make a classification label list encoding our 4 classes **\n",
        "\n",
        "###############################################################33remmember up\n",
        "encoded_emotions_training=[]\n",
        "for j in data_training['emotion']:\n",
        "  if j == \"anger\":\n",
        "    encoded_emotions_training.append([1,0,0,0])\n",
        "  elif j == \"fear\":\n",
        "    encoded_emotions_training.append([0,1,0,0])\n",
        "  elif j == \"sadness\":\n",
        "    encoded_emotions_training.append([0,0,1,0])\n",
        "  elif j == \"joy\":\n",
        "    encoded_emotions_training.append([0,0,0,1])\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h81s34mXXx8"
      },
      "source": [
        "encoded_emotions_test=[]\n",
        "for j in data_test['emotion']:\n",
        "  if j == \"anger\":\n",
        "    encoded_emotions_test.append([1,0,0,0])\n",
        "  elif j == \"fear\":\n",
        "    encoded_emotions_test.append([0,1,0,0])\n",
        "  elif j == \"sadness\":\n",
        "    encoded_emotions_test.append([0,0,1,0])\n",
        "  elif j == \"joy\":\n",
        "    encoded_emotions_test.append([0,0,0,1])\n",
        "  else:\n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjhPG1mitN6E"
      },
      "source": [
        "encoded_emotions_training = list(encoded_emotions_training)\n",
        "encoded_emotions_test = list(encoded_emotions_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKm6GOK6hcII"
      },
      "source": [
        "Shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BoYcvrNhFaP"
      },
      "source": [
        "import random\n",
        "train = list(zip(X_train_pad, encoded_emotions_training))\n",
        "test = list(zip(x_test_pad, encoded_emotions_test))\n",
        "\n",
        "X_train_pad, encoded_emotions_training = zip(*train)\n",
        "x_test_pad, encoded_emotions_test = zip(*test)\n",
        "\n",
        "\n",
        "random.shuffle(train)\n",
        "random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU_s001k1y0N"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkJB-oBAMADD"
      },
      "source": [
        "**CNN**\n",
        "\n",
        "using TensorFlow to build the convolutional neural network for text classification\n",
        "\n",
        "**1-D Convolutions over text**\n",
        "The convolution network will be made of of the following:\n",
        "\n",
        "- An embedding layer that turns the data into dense vectors of fixed size. More on this later.\n",
        "- A `Conv1D` with 128 units with the `relu` activation function.\n",
        "- A `GlobalMaxPooling1D` layer that downsamples the input by taking the maximum value.\n",
        "- A `Dense` layer with 10 units for the fully connected layer.\n",
        "- An output layer with the sigmoid activation function because this is a binary problem.\n",
        "\n",
        "**Data In CNN**\n",
        "\n",
        "As seen earlier, the data has to be converted in some numerical representation.\n",
        " The `one_hot` function can be used to do this.\n",
        "The function will encode the reviews into a list of integers. It expects the following arguments:\n",
        "\n",
        "- `text` that is the text to be encoded\n",
        "- `n` the size of the vocabulary\n",
        "- `filters` specify the characters to be removed from the reviews such as punctuation marks and any other special characters\n",
        "- `lower` indicates if the reviews should be converted to lower case or not\n",
        "- `split` dictates how the reviews should be split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cayqbW6f0PFx"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.layers import Conv1D , Input , Flatten\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKEIU0yy0onN"
      },
      "source": [
        "# A integer input for vocab indices.\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "max_features=1000\n",
        "embedding_dim = 50\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Conv1D + global max pooling\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# I added a vanilla hidden layer:\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "predictions = layers.Dense(4, activation=\"sigmoid\", name=\"predictions\")(x)\n",
        "\n",
        "model_1 = keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "#model_1.compile(loss=\"SoftMax\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqp29iRn0oxI"
      },
      "source": [
        "#prepare the model for training. Let’s apply the common `Adam` optimizer and the `binary_crossentropy` loss function.\n",
        "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6y2X17sKlT"
      },
      "source": [
        "x_test_pad=np.array(x_test_pad)\n",
        "X_train_pad=np.array(X_train_pad)\n",
        "encoded_emotions_training=np.array(encoded_emotions_training)\n",
        "encoded_emotions_test=np.array(encoded_emotions_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAXGZDd10o6U",
        "outputId": "d154aac3-5aea-4833-df52-22ed61dd7099"
      },
      "source": [
        "# Fit the model using the train and test datasets.\n",
        "model_1.fit(X_train_pad, encoded_emotions_training, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3688 - accuracy: 0.3186\n",
            "Epoch 2/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3690 - accuracy: 0.3188\n",
            "Epoch 3/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3689 - accuracy: 0.3188\n",
            "Epoch 4/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3691 - accuracy: 0.3186\n",
            "Epoch 5/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3697 - accuracy: 0.3180\n",
            "Epoch 6/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3694 - accuracy: 0.3186\n",
            "Epoch 7/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3688 - accuracy: 0.3188\n",
            "Epoch 8/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3691 - accuracy: 0.3186\n",
            "Epoch 9/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3690 - accuracy: 0.3188\n",
            "Epoch 10/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3697 - accuracy: 0.3186\n",
            "Epoch 11/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3690 - accuracy: 0.3183\n",
            "Epoch 12/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3695 - accuracy: 0.3183\n",
            "Epoch 13/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3691 - accuracy: 0.3188\n",
            "Epoch 14/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3688 - accuracy: 0.3188\n",
            "Epoch 15/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3689 - accuracy: 0.3180\n",
            "Epoch 16/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3691 - accuracy: 0.3183\n",
            "Epoch 17/20\n",
            "113/113 [==============================] - 4s 37ms/step - loss: 1.3694 - accuracy: 0.3183\n",
            "Epoch 18/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3691 - accuracy: 0.3188\n",
            "Epoch 19/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3690 - accuracy: 0.3191\n",
            "Epoch 20/20\n",
            "113/113 [==============================] - 4s 38ms/step - loss: 1.3691 - accuracy: 0.3183\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd1ca1a1690>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_Nt_wGp0pCq",
        "outputId": "7551c23b-bb42-462b-bcc0-d0d82469c276"
      },
      "source": [
        "print(model_1.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, None, 50)          50000     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, None, 50)          0         \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, None, 128)         44928     \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, None, 128)         114816    \n",
            "                                                                 \n",
            " global_max_pooling1d_5 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 226,772\n",
            "Trainable params: 226,772\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuj4djcA0pLi"
      },
      "source": [
        "result_1 = model_1.predict(x_test_pad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b0HZaRpvy-N",
        "outputId": "44062518-4c03-468a-fa22-f55dfba61beb"
      },
      "source": [
        "result_1[1:5] , encoded_emotions_test[1:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.48944637, 0.55891037, 0.46867815, 0.4767882 ],\n",
              "        [0.48944637, 0.55891037, 0.46867815, 0.4767882 ],\n",
              "        [0.48944637, 0.55891037, 0.46867815, 0.4767882 ],\n",
              "        [0.48944637, 0.55891037, 0.46867815, 0.4767882 ]], dtype=float32),\n",
              " array([[1, 0, 0, 0],\n",
              "        [1, 0, 0, 0],\n",
              "        [1, 0, 0, 0],\n",
              "        [1, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1URqvLWv9_6",
        "outputId": "836190fb-2f35-47e8-a485-9f799ae30c33"
      },
      "source": [
        "model_1.evaluate(x_test_pad, encoded_emotions_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 1s 8ms/step - loss: 1.4137 - accuracy: 0.3176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4137200117111206, 0.3176320791244507]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4TYcmoUT6C_"
      },
      "source": [
        "\n",
        "#Defining the model to be optimized\n",
        "vocab_size =[]\n",
        "max_length = []\n",
        "#def model_to_optimize(num_filters, kernel_size): #**optimization** in TensorFlow  a Scikit-learn wrapper enables  to apply grid search to a neural network.\n",
        "\n",
        " # model = Sequential([\n",
        " # embedding_layer,\n",
        " # Conv1D(num_filters, kernel_size, activation='relu'),\n",
        " # GlobalMaxPooling1D(),\n",
        " # Dense(10, activation='relu'),\n",
        " # Dense(1, activation='sigmoid')])\n",
        " # model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "  #return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}